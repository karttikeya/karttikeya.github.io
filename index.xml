<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Karttikeya Mangalam on Karttikeya Mangalam</title>
    <link>https://karttikeya.github.io/</link>
    <description>Recent content in Karttikeya Mangalam on Karttikeya Mangalam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Karttikeya Mangalam</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Future Person Localization in First-Person Videos</title>
      <link>https://karttikeya.github.io/publication/future-localization/</link>
      <pubDate>Mon, 18 Jun 2018 18:48:06 +0900</pubDate>
      
      <guid>https://karttikeya.github.io/publication/future-localization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Future Person Localization in First-Person Videos</title>
      <link>https://karttikeya.github.io/project/tokyo/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/tokyo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automated Modelling for Course Recommendation (C.R.A.M)</title>
      <link>https://karttikeya.github.io/project/cram/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/cram/</guid>
      <description>&lt;p&gt;Developed a Machine Learning based recommendation webapp for IIT Kanpur UG students for institute course selection (aided by additional recommendations for courses on EdX, coursera etc.) and personalised academic template based on research interests,previous internships and courses undertaken. Mined student resumes and CV in public domain for previous 10 years using text analysis for developing a database. Used collaborative filetring and nearest neighbours for recommendation.&lt;br&gt;
Complete design and implementation in 24 hours and won OVERALL WINNER in Google DevFest 2016. Final Presentation &lt;a href=&#34;https://karttikeya.github.io/pdf/cram.pdf&#34; target=&#34;_blank&#34;&gt;slides&lt;/a&gt; and &lt;a href=&#34;https://github.com/shivrai/CRAM&#34; target=&#34;_blank&#34;&gt;code&lt;/a&gt; are public.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cellular Automata for Image Processing</title>
      <link>https://karttikeya.github.io/project/ca-ip/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/ca-ip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compressing U-net using Knowledge Distillation </title>
      <link>https://karttikeya.github.io/project/epfl/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/epfl/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://sigtuple.com/wp-content/uploads/2017/05/unet.png&#34; alt=&#34;Mountain View&#34;&gt;
This is my Master&amp;rsquo;s Research project mentored by &lt;a href=&#34;https://people.epfl.ch/mathieu.salzmann&#34; target=&#34;_blank&#34;&gt;Dr. Mathieu Salzmann&lt;/a&gt; at &lt;a href=&#34;https://people.epfl.ch/pascal.fua/bio?lang=en&#34; target=&#34;_blank&#34;&gt;Prof. Pascal Fua&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://cvlab.epfl.ch/&#34; target=&#34;_blank&#34;&gt;Computer Vision Lab&lt;/a&gt; at &lt;a href=&#34;https://www.epfl.ch/&#34; target=&#34;_blank&#34;&gt;École polytechnique fédérale de Lausanne&lt;/a&gt;, Switzerland. We focus on compressing Fully Convolutional Networks wit skip connections such as the U-net or the Stacked Hourglass Network with minimal loss in performance using Knowledge Distillation (original &lt;a href=&#34;https://arxiv.org/abs/1503.02531&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt; by Hinton et al.). Alongwith proposnig minor changes in the U-net architecture to improve performance, such as introduction of Batch Normalization layer, we compress the original Unet architecture with over 31 Million traininable parameters to just 30,900 paramters (over 100x compression!).  &lt;br&gt;&lt;/p&gt;

&lt;p&gt;The project report and presentation slides are available &lt;a href=&#34;https://karttikeya.github.io/pdf/unet_report.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://karttikeya.github.io/pdf/unet_slides.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. Also, entire codebase (U-net architecture in Pytorch + Distillation code) is available on &lt;a href=&#34;https://github.com/karttikeya/Unet-Distillation&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Emotion Recognition from Static Human facial Images</title>
      <link>https://karttikeya.github.io/project/emo-recog/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/emo-recog/</guid>
      <description>&lt;p&gt;This was our project for &lt;a href=&#34;https://www.cse.iitk.ac.in/users/piyush/courses/ml_autumn16/ML.html&#34; target=&#34;_blank&#34;&gt;CS771A&lt;/a&gt; - Machine Learning Techniques,Fall 2016. We implemented various supervied classifiers such as naive bayes, Kernelized SVMs etc. for emotion classification on human facial Images from the &lt;a href=&#34;https://sites.google.com/site/emotiw2016/&#34; target=&#34;_blank&#34;&gt;Emotion Recognition in the Wild Challenge 2016&lt;/a&gt; dataset. &lt;br&gt;
 For supervised classifiers, we engineered suitable feature vectors using Google Cloud Vision API and annotated the ground truth in a semi-supervised fashion using Cloud Visio API and human supervision. Futher we compared the performance of traditional classification approaches against results from pre-trained Convolutional Neural Networks in our project&amp;rsquo;s &lt;a href=&#34;https://karttikeya.github.io/pdf/CS771-report.pdf&#34; target=&#34;_blank&#34;&gt;final report&lt;/a&gt;. Also, the slides for the presentation are available &lt;a href=&#34;https://karttikeya.github.io/pdf/CS771-slides.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image Prcessing for Autonomous Underwater Vehicle, Robotics Club, IIT Kanpur</title>
      <link>https://karttikeya.github.io/project/ip-auv/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/ip-auv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Solutions To Non-Causal Difference Equations </title>
      <link>https://karttikeya.github.io/project/cau-diff/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/cau-diff/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Speech based synchrony measuerement in dyadic interaction</title>
      <link>https://karttikeya.github.io/project/mme-conv/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/mme-conv/</guid>
      <description>&lt;p&gt;We aim to develop a measure for engagement/synchrony between two human speakers in a face to face conversation processing vaiorus modalities like audio-visual clues and gestures using emotion recognition and sentiment analysis. We are using the &lt;a href=&#34;http://sail.usc.edu/iemocap/&#34; target=&#34;_blank&#34;&gt;IEMOCAP&lt;/a&gt; database for our research purpose. &lt;br&gt;&lt;/p&gt;

&lt;p&gt;As a baseline model, my work as undergraduate research project for Vth and VIth semester (junior year) focuses using the speech clues for learning the synchrony present in the audio signal between speakers. Discete Time Warping is suggested as a measure for syncrony for speech signals. &lt;br&gt; This preliminary &lt;a href=&#34;https://karttikeya.github.io/pdf/ugp.pdf&#34; target=&#34;_blank&#34;&gt;project report&lt;/a&gt; details our approach and assumptions. This research is still in progress.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Do deep neural networks learn shallow learnable examples first?</title>
      <link>https://karttikeya.github.io/publication/deep-shallow/</link>
      <pubDate>Sun, 18 Jun 2017 18:48:06 +0900</pubDate>
      
      <guid>https://karttikeya.github.io/publication/deep-shallow/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bitwise Operations of Cellular Automaton on Gray-scale Images</title>
      <link>https://karttikeya.github.io/publication/bitwise-operations-of-cellular-automaton-on-grayscale-images---copy/</link>
      <pubDate>Sat, 18 Jun 2016 18:48:06 +0900</pubDate>
      
      <guid>https://karttikeya.github.io/publication/bitwise-operations-of-cellular-automaton-on-grayscale-images---copy/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hybrid Recommender Systems using feature selection by Markov Blanket</title>
      <link>https://karttikeya.github.io/project/bg/</link>
      <pubDate>Sat, 21 Jul 2012 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/bg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Spontaneity to Improve Emotion Recognition in Speech</title>
      <link>https://karttikeya.github.io/publication/emotion-spontaneity/</link>
      <pubDate>Sat, 18 Jun 2011 18:48:06 +0900</pubDate>
      
      <guid>https://karttikeya.github.io/publication/emotion-spontaneity/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
