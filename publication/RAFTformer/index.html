<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Noto Sans" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Google Sans" rel="stylesheet">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Latency Matters: Real-Time Action Forecasting Transformer</title>
</head>
<body class="h-100 d-flex flex-column dark-bg custom-light">
    <main class="container flex-grow-1">
        <header class="py-3">
            <h2 class="custom-title text-light mt-3">
                Latency Matters: Real-Time Action Forecasting Transformer
            </h2>
            <div class="authors mt-3">
                <div class="px-3">
                    <a href="https://www.linkedin.com/in/harshayu-girase-764b06153">Harshayu Girase</a>
                    <span><sup>1,2</sup>*</span>
                </div>
                <div class="px-3">
                    <a href="https://lukan94.github.io/">Nakul Agarwal</a>
                    <sup>1</sup>
                </div>
                <div class="px-3">
                    <a href="https://chihochoi.github.io/">Chiho Choi</a>
                    <sup>1</sup>
                </div>
                <div class="px-3">
                    <a href="https://karttikeya.github.io/">Karttikeya Mangalam</a>
                    <span><sup>2</sup>*</span>
                </div>
            </div>
            <div class="mt-1">
                <span><small>* denotes equal technical contribution</small></span>
            </div>
            <div class="insts custom-text mt-1">
                <div class="px-2"><sup>1</sup>Honda Research Institute USA</div>
                <div class="px-2"><sup>2</sup>UC Berkeley</div>
            </div>
            <div class="mt-3">
                <span class="mx-1">
                    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf" class="btn btn-dark rounded-pill">
                      <i class="fas fa-file-pdf"></i>
                      <span>Paper</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="https://www.youtube.com/watch?v=0tbK36hzSM0" class="btn btn-dark rounded-pill">
                      <i class="fab fa-youtube"></i>
                      <span>Video</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fab fa-github"></i>
                      <span>Code</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="fas fa-chalkboard"></i>
                      <span>Slides</span>
                    </a>
                </span>
                <span class="mx-1">
                    <a href="" class="btn btn-dark rounded-pill">
                      <i class="far fa-clipboard"></i>
                      <span>Poster</span>
                    </a>
                </span>
            </div>
        </header>
        <div style="max-width:70%;margin:auto">
            <section id="graph">
                <h3 class="text-center text-light headline mt-5 mb-3">
                    Bigger Models are <span class="accent-color">NOT</span> Necessarily Better
                </h3>
                <p class="text-justify">
                    In this paper, we propose a <i>new real-time setting</i> for evaluating action forecasting networks where bigger models do not 
                    necessarily achieve a better performance. Current state-of-the-art methods trend towards increasing model size for higher fidelity 
                    forecasts, ignoring the cost of increased latency. The new latency-aware real-time setting better mimics practical deployment settings 
                    for embodied forecasting systems, paving the path for the development of latency-aware forecasting models in the future.
                </p>
                <div class="row px-1 my-3">
                    <div class="col"></div>
                    <div class="col-7"><img class="border-0 custom-rounded" src="images/tradeoff.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    The graph above shows a clear trade-off between latency and high-fidelity forecasts in the real-time evaluation setting.
                    We observe that bigger models continue to perform better in latency agnostic offline settings. However, <span class="accent-color"> in the 
                    real-time setting, models with very high latency (big models) gradually perform worse due to limited access to the most recent video data. </span>
                </p>
            </section>
            <section id="video">
                <h3 class="text-center text-light mt-4 mb-2">
                    Video
                </h3>
                <div class="row px-1 my-2">
                    <div class="col"></div>
                    <div class="border-0 custom-rounded embed-responsive embed-responsive-16by9 col-10">
                        <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/0tbK36hzSM0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="diagram">
                <h3 class="text-center text-light mt-4 mb-3">
                    Overview of Real-Time Evaluation Setting
                </h3>
                <div class="row px-1 mb-3">
                    <div class="col"></div>
                    <div class="col-6"><img class="border-0 custom-rounded" src="images/real-time-eval.png" alt="" style="max-width:100%"></div>
                    <div class="col"></div>
                </div>
                <p class="text-justify">
                    This diagram details the difference between offline and real-time evaluation. During offline evaluation, 
                    inference latency is assumed to be zero, allowing predictions to be made at any time step using all prior frames up to the 
                    forecasting horizon. During real-time evaluation, the nonzero inference latency of the model must be accounted for. In this 
                    setting, predictions must be made using frames further in the past. A model with reduced latency is able to leverage 
                    significantly more recent frames than prior methods, leading to more accurate predictions.
                </p>
            </section>
            <section id="abstract">
                <div class="row mt-4">
                    <div class="col"></div>
                    <div class="col-10 border-0 custom-rounded bg-dark">
                        <div class="row">
                            <div class="col"></div>
                            <a class="col btn-dropdown" id="dropdown-container" data-toggle="collapse" href="#collapseAbstract" role="button" aria-expanded="false" aria-controls="collapseAbstract">
                                <i class="fas fa-caret-down fa-2xs" id="caret-icon"></i>
                                <span>Abstract</span>
                            </a>
                            <div class="col"></div>
                        </div>
                        <div class="collapse" id="collapseAbstract">
                            <p class="text-justify mx-2 mb-4">
                                We present RAFTformer, a real-time action forecasting transformer for latency-aware real-world action forecasting. 
                                RAFTformer is a two-stage fully transformer based architecture comprising of a video transformer backbone that 
                                operates on high resolution, short-range clips, and a head transformer encoder that temporally aggregates 
                                information from multiple short-range clips to span a long-term horizon. Additionally, we propose a novel 
                                self-supervised shuffled causal masking scheme as a model level augmentation to improve forecasting fidelity. 
                                Finally, we also propose a novel real-time evaluation setting for action forecasting that directly couples model 
                                inference latency to overall forecasting performance and brings forth a hitherto overlooked trade-off between 
                                latency and action forecasting performance. Our parsimonious network design facilitates RAFTformer inference latency 
                                to be 9x smaller than prior works at the same forecasting accuracy. Owing to its two-staged design, RAFTformer uses 
                                94% less training compute and 90% lesser training parameters to outperform prior state-of-the-art baselines by 4.9 
                                points on EGTEA Gaze+ and by 1.4 points on EPIC-Kitchens100 validation set, as measured by Top-5 recall (T5R) in the 
                                offline setting. In the real-time setting, RAFTformer outperforms prior works by an even greater margin of up to 4.4 
                                T5R points on the EPIC-Kitchens-100 dataset.
                            </p>
                        </div>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
            <section id="fyi">
                <p class="mt-4">
                    We also introduce RAFTformer, an architecture that beats prior state-of-the-art action forecasting methods with a huge reduction 
                    in latency. Please see the paper for further details.
                </p>
            </section>
            <section id="results">
                <div class="row mt-4">
                    <div class="col"></div>
                    <div class="col-10 border-0 custom-rounded bg-dark">
                        <div class="row">
                            <div class="col"></div>
                            <a class="col btn-dropdown" id="dropdown-container-2" data-toggle="collapse" href="#collapseResults" role="button" aria-expanded="false" aria-controls="collapseResults">
                                <i class="fas fa-caret-down fa-2xs" id="caret-icon-2"></i>
                                <span>Results</span>
                            </a>
                            <div class="col"></div>
                        </div>
                        <div class="collapse" id="collapseResults">
                            <div class="row px-1 my-2">
                                <div class="col gx-3"></div>
                                <div class="col-10 gx-3"><img class="border-0 rounded" src="images/EK-offline.png" alt="" style="max-width:100%"></div>
                                <div class="col gx-3"></div>
                            </div>
                            <p class="text-justify mx-2 mb-4">
                                The above table displays offline evaluation results on the EPIC-Kitchens-100 dataset for a one second forecasting horizon. 
                                <span class="accent-color">RAFTformer matches previous state-of-the-art models in action T5R while reducing latency by 9x, 
                                parameters by 8x, and training time in GPU hours by 94%.</span> RAFTformer-2B, which combines two separate RAFTformer models 
                                to train a two-backbone model, achieves state-of-the-art results by a 1.4% T5R increase. 
                            </p>
                            <div class="row px-1 my-2">
                                <div class="col gx-3"></div>
                                <div class="col-10 gx-3"><img class="border-0 rounded" src="images/EK-online.png" alt="" style="max-width:100%"></div>
                                <div class="col gx-3"></div>
                            </div>
                            <p class="text-justify mx-2 mb-4">
                                This table displays real-time evaluation results on the EPIC-Kitchens-55 dataset. Each comparison is performed between a pair 
                                of models with their inference start times adjusted to account for latency such that they produce the forecasting output 
                                simultaneously. In this setting, faster models can pragmatically utilize recent frames while slower models must rely on higher 
                                fidelity prediction from older frames. <span class="accent-color">We observe that RAFTformer outperforms prior methods by an 
                                <i>even larger</i> margin in the real-time evaluation setting than in the offline setting.</span>
                            </p>
                        </div>
                    </div>
                    <div class="col"></div>
                </div>
            </section>
        </div>
        <section id="BibTeX" style="max-width:80%;margin:auto">
            <div class="container is-max-desktop content">
                <h3 class="text-center text-light mt-4 mb-2">
                    BibTeX
                </h3>
                <pre class="bibtex p-3 bg-dark text-light border-0 custom-rounded"><code>@inproceedings{girase2023latency,
    title     = {Latency Matters: Real-Time Action Forecasting Transformer},
    author    = {Girase, Harshayu and Agarwal, Nakul and Choi, Chiho and Mangalam, Karttikeya},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages     = {18759--18769},
    year      = {2023}
}</code></pre>
            </div>
        </section>
        <div class="mb-5" style="max-width:70%;margin:auto">

            <!-- <section id="ack">
                <h3 class="text-center text-light mt-4 mb-2">
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore 
                    magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo 
                    consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. 
                    Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
                </p>
            </section> -->
        </div>
    </main>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <script src="https://kit.fontawesome.com/3aef636b73.js" crossorigin="anonymous"></script>
    <script src="script.js"></script>
</body>
</html>