<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ri on Karttikeya Mangalam</title>
    <link>https://karttikeya.github.io/tags/ri/</link>
    <description>Recent content in Ri on Karttikeya Mangalam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Karttikeya Mangalam</copyright>
    <lastBuildDate>Sun, 07 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://karttikeya.github.io/tags/ri/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Future Person Localization in First-Person Videos</title>
      <link>https://karttikeya.github.io/project/tokyo/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/tokyo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cellular Automata for Image Processing</title>
      <link>https://karttikeya.github.io/project/ca-ip/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/ca-ip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compressing U-net using Knowledge Distillation </title>
      <link>https://karttikeya.github.io/project/epfl/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/epfl/</guid>
      <description>This is my Master&amp;rsquo;s Research project mentored by Dr. Mathieu Salzmann at Prof. Pascal Fua&amp;rsquo;s Computer Vision Lab at École polytechnique fédérale de Lausanne, Switzerland. We focus on compressing Fully Convolutional Networks wit skip connections such as the U-net or the Stacked Hourglass Network with minimal loss in performance using Knowledge Distillation (original paper by Hinton et al.). Alongwith proposnig minor changes in the U-net architecture to improve performance, such as introduction of Batch Normalization layer, we compress the original Unet architecture with over 31 Million traininable parameters to just 30,900 paramters (over 100x compression!</description>
    </item>
    
    <item>
      <title>Speech based synchrony measuerement in dyadic interaction</title>
      <link>https://karttikeya.github.io/project/mme-conv/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://karttikeya.github.io/project/mme-conv/</guid>
      <description>We aim to develop a measure for engagement/synchrony between two human speakers in a face to face conversation processing vaiorus modalities like audio-visual clues and gestures using emotion recognition and sentiment analysis. We are using the IEMOCAP database for our research purpose. As a baseline model, my work as undergraduate research project for Vth and VIth semester (junior year) focuses using the speech clues for learning the synchrony present in the audio signal between speakers.</description>
    </item>
    
  </channel>
</rss>